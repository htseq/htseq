import multiprocessing
import operator
import sys
import itertools
import numpy as np
import pysam
import random
import HTSeq

from HTSeq.scripts.count_reads_in_feature.parameters import CountParameters
from HTSeq.scripts.count_reads_in_feature.count_reads_per_file import (
    count_reads_single_file
)
from HTSeq.scripts.utils import (
    UnknownChrom,
    invert_strand
)

def do_count_reads_in_features(in_param):
    """
    I am the new version of count_reads_in_features.

    Count reads in features, parallelizing by file

    Parameters
    ----------
    in_param : CountParameters
        Custom object (see parameters module) which stores the
        input parameters given by user to run htseq-count.
    """

    nprocesses = min(in_param.nprocesses, len(in_param.sam_filenames))

    in_param.prepare_features()

    # prepare to run count in parallel
    args = in_param.get_args_for_count()

    # Count reads in parallel
    if nprocesses > 1:
        results = run_parallel_count_reads(nprocesses, args)
    else:
        results = run_serial_count_reads(args)

    in_param.write_results(results)

def run_serial_count_reads(args):
    """
    Run the count reads feature in serial, i.e. 1 file at the time.

    Parameters
    ----------
    args : array
        Array containing the arguments for the counting function.
        This should be the array generated by count_reads_in_feature.parameters'
        get_args_for_count function.

    Returns
    -------
    results : array
        Array of dictionaries, with each dictionary being generated by
        count_reads_single_file function.
    """
    # May seem a bit wasteful throwing just 1 line of code into a function,
    # but in the case this gets more complicated in the future, it can be
    # contained here.
    results = list(itertools.starmap(count_reads_single_file, args))
    return results

def run_parallel_count_reads(nprocesses, args):
    """
    Run the count reads feature in parallel (1 file per core)

    Parameters
    ----------
    nprocesses : int
        Number of parallel CPU processes to use.

    args : array
        Array containing the arguments for the counting function.
        This should be the array generated by count_reads_in_feature.parameters'
        get_args_for_count function.

    Returns
    -------
    results : array
        Array of dictionaries, with each dictionary being generated by
        count_reads_single_file function.
        Array is sorted by isam_file_idx in the args parameter.
        See count_reads_in_feature.parameters' get_args_for_count function.
    """
    with multiprocessing.Pool(nprocesses) as pool:
        results = pool.starmap(count_reads_single_file, args)
    results.sort(key=operator.itemgetter('isam_file_idx'))
    return results
