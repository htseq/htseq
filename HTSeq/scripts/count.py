import multiprocessing
import operator
import warnings
import traceback
import os.path
import sys
import itertools
import numpy as np

import HTSeq
from HTSeq.scripts.count_reads_in_feature.parameters import (
    CountParameters,
    process_cmd_line_options
)
from HTSeq.scripts.utils import (
    my_showwarning,
    _write_output
)
from HTSeq.scripts.count_reads_in_feature.count_reads_per_file import (
    count_reads_single_file
)

def main():
    """
    Main function which runs htseq-count. This is the main function that is
    called by the htseq-count command line.
    """

    # A lot is happening in this function, but it essentially:
    # 1. Create an ArgumentParser object pre-filled with the default description of HTSeq.
    # 2. Display htseq version installed if --version flag is used.
    # 3. Process all the command-line options supplied to htseq-count command.
    # 4. Return these options as the attributes of an object (args below.)
    # See count_reads_in_feature/parameters.py file for more info.
    # Note, if you want to remove/modify/add a command-line option, please
    # modify this function.
    args = process_cmd_line_options()

    # Show warning message?
    warnings.showwarning = my_showwarning

    # What do I do? I take all the command-line options and turn them into a
    # self-contained object used by the actual count function.
    # CountParameters is defined in count_reads_in_feature/parameters.py
    parameters = CountParameters(arg_parser_obj = args)

    try:
        # I'm the one who does the actual count function.
        # I'm within count_reads_in_feature/core.py script.
        count_reads_mapped_to_features(parameters)
    except:
        sys.stderr.write("  %s\n" % str(sys.exc_info()[1]))
        sys.stderr.write("  [Exception type: %s, raised in %s:%d]\n" %
                         (sys.exc_info()[1].__class__.__name__,
                          os.path.basename(traceback.extract_tb(
                              sys.exc_info()[2])[-1][0]),
                          traceback.extract_tb(sys.exc_info()[2])[-1][1]))
        sys.exit(1)

def count_reads_mapped_to_features(in_param):
    """
    I am the new version of count_reads_in_features.

    Count reads in features, parallelizing by file

    Parameters
    ----------
    in_param : CountParameters
        Custom object (see parameters module) which stores the
        input parameters given by user to run htseq-count.
    """

    nprocesses = min(in_param.nprocesses, len(in_param.sam_filenames))

    in_param.prepare_features()

    # prepare to run count in parallel
    args = in_param.get_args_for_count()

    # Count reads in parallel
    if nprocesses > 1:
        results = run_parallel_count_reads(nprocesses, args)
    else:
        results = run_serial_count_reads(args)

    _write_output(
        results,
        in_param.sam_filenames,
        in_param.attributes,
        in_param.additional_attributes,
        in_param.output_filename,
        in_param.output_delimiter,
        in_param.output_append,
        sparse = in_param.counts_output_sparse,
        dtype = np.float32
    )

def run_serial_count_reads(args):
    """
    Run the count reads feature in serial, i.e. 1 file at the time.

    Parameters
    ----------
    args : array
        Array containing the arguments for the counting function.
        This should be the array generated by count_reads_in_feature.parameters'
        get_args_for_count function.

    Returns
    -------
    results : array
        Array of dictionaries, with each dictionary being generated by
        count_reads_single_file function.
    """
    # May seem a bit wasteful throwing just 1 line of code into a function,
    # but in the case this gets more complicated in the future, it can be
    # contained here.
    results = list(itertools.starmap(count_reads_single_file, args))
    return results

def run_parallel_count_reads(nprocesses, args):
    """
    Run the count reads feature in parallel (1 file per core)

    Parameters
    ----------
    nprocesses : int
        Number of parallel CPU processes to use.

    args : array
        Array containing the arguments for the counting function.
        This should be the array generated by count_reads_in_feature.parameters'
        get_args_for_count function.

    Returns
    -------
    results : array
        Array of dictionaries, with each dictionary being generated by
        count_reads_single_file function.
        Array is sorted by isam_file_idx in the args parameter.
        See count_reads_in_feature.parameters' get_args_for_count function.
    """
    with multiprocessing.Pool(nprocesses) as pool:
        results = pool.starmap(count_reads_single_file, args)
    results.sort(key=operator.itemgetter('isam_file_idx'))
    return results

if __name__ == "__main__":
    main()
